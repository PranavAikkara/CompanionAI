{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS THE FINAL VERSION OF THE MODEL WHERE ALL PROCESSES WILL TAKE PLACE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\aikka\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aikka\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import tensorflow as tp # type: ignore\n",
    "from transformers import XLNetTokenizer, TFXLNetModel # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset # type: ignore\n",
    "ds = load_dataset(\"Estwld/empathetic_dialogues_llm\")\n",
    "type(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_id': 'hit:53_conv:107', 'situation': 'I really want to win the lottery someday, maybe i will? ', 'emotion': 'hopeful', 'conversations': [{'content': 'So this is going to sound crazy but, one day I am going to win the lottery. ', 'role': 'user'}, {'content': 'That would pretty amazing. What will you do with the winning?', 'role': 'assistant'}, {'content': 'Pay off my debts from moving number 1, and then buy a house! What would you do with the money? ', 'role': 'user'}, {'content': 'I think the same really. Making sure everything is paid off, having a roof over your head, etc... is what most people would want to take caer of first.', 'role': 'assistant'}]}\n",
      "{'conv_id': 'hit:469_conv:939', 'situation': 'Whenever I hear certain songs, it brings back so many memories. Mostly of when I was young and dumb staying up late with friends.', 'emotion': 'nostalgic', 'conversations': [{'content': 'Have you ever heard a song on the radio and it just takes you back to a different time? Like an escape?', 'role': 'user'}, {'content': 'All the time.  That is part of listening to music I suppose.  The songs remind you of when you first heard them.', 'role': 'assistant'}, {'content': \"Yeah, I guess that's fair. It happens all the time to me too. Sometimes makes me wish I was reliving those moments but I don't think I would really want to go back..\", 'role': 'user'}, {'content': 'I know what you mean.  However, the older I get the more I want to go back LOL.', 'role': 'assistant'}, {'content': \"lol :) That's true. Life is hard and did seem so much more carefree when I was younger, but I just don't like who I was. I like me now much better :)\", 'role': 'user'}]}\n",
      "{'conv_id': 'hit:331_conv:663', 'situation': 'I had a huge exam that was coming up, and I study for weeks for it', 'emotion': 'prepared', 'conversations': [{'content': 'I had a huge exam that like 25 percent of my grade. I study for 2 weeks for it', 'role': 'user'}, {'content': 'Oh, I bet that was very stressful and difficult. I hope you did well on it?', 'role': 'assistant'}, {'content': \"Yeah because the professor got mad that the book store didn't have the little blue books to write in, so he canceled it and said whatever our current grade was to bump it up a letter grade\", 'role': 'user'}, {'content': \"Well, at least you didn't go down in your grade. But, it wasn't right to treat the students like that!\", 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "print(ds['train'][91])\n",
    "print(ds['test'][100])\n",
    "print(ds['valid'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['conv_id', 'situation', 'emotion', 'conversations'],\n",
      "        num_rows: 19533\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['conv_id', 'situation', 'emotion', 'conversations'],\n",
      "        num_rows: 2770\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['conv_id', 'situation', 'emotion', 'conversations'],\n",
      "        num_rows: 2547\n",
      "    })\n",
      "})\n",
      "{'conv_id': Value(dtype='string', id=None), 'situation': Value(dtype='string', id=None), 'emotion': Value(dtype='string', id=None), 'conversations': [{'content': Value(dtype='string', id=None), 'role': Value(dtype='string', id=None)}]}\n"
     ]
    }
   ],
   "source": [
    "print(ds)\n",
    "print(ds['train'].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ds['train']\n",
    "type(data)\n",
    "#print(data)\n",
    "#DATA SET IS IN ARROW FORMAT BECAUSE HUGGING FACE USES IT TO EASILY TRANSFER DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONVERTED THE ARROW DATASET INTO PANDAS\n",
    "dftrain = ds['train'].to_pandas()\n",
    "dftest = ds['test'].to_pandas()\n",
    "dfvalid = ds['valid'].to_pandas()\n",
    "type(dftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>situation</th>\n",
       "      <th>emotion</th>\n",
       "      <th>conversations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>[{'content': 'I remember going to see the fire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:1_conv:2</td>\n",
       "      <td>i used to scare for darkness</td>\n",
       "      <td>afraid</td>\n",
       "      <td>[{'content': ' it feels like hitting to blank ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id                                          situation  \\\n",
       "0  hit:0_conv:1  I remember going to the fireworks with my best...   \n",
       "1  hit:1_conv:2                       i used to scare for darkness   \n",
       "\n",
       "       emotion                                      conversations  \n",
       "0  sentimental  [{'content': 'I remember going to see the fire...  \n",
       "1       afraid  [{'content': ' it feels like hitting to blank ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)  \n",
    "dftrain.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_id': 'hit:1_conv:2', 'situation': ' i used to scare for darkness', 'emotion': 'afraid', 'conversations': [{'content': ' it feels like hitting to blank wall when i see the darkness', 'role': 'user'}, {'content': \"Oh ya? I don't really see how\", 'role': 'assistant'}, {'content': 'dont you feel so.. its a wonder ', 'role': 'user'}, {'content': 'I do actually hit blank walls a lot of times but i get by', 'role': 'assistant'}, {'content': ' i virtually thought so.. and i used to get sweatings', 'role': 'user'}, {'content': 'Wait what are sweatings', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "type(data)\n",
    "print(ds['train'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset made into a csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftrain.to_csv(\"dataset_Train.csv\", index=False)\n",
    "#dftest.to_csv(\"dataset_Test.csv\", index= False)\n",
    "#dfvalid.to_csv(\"dataset_Valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba835a726a74f6682188bf537b823fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13847cf6d44b49afa8cf28b7f2ee5ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f67bd5406a4bc7a943e5824681bc22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45f6e70eb9e493c8847fc77a4ede891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/565M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aikka\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aikka\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\initializers\\initializers.py:121: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFXLNetModel.from_pretrained(\"xlnet-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
