{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS THE FINAL VERSION OF THE MODEL WHERE ALL PROCESSES WILL TAKE PLACE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import tensorflow as tf #type: ignore\n",
    "import torch\n",
    "#import sentencepiece #type:ignore\n",
    "import evaluate #type:ignore\n",
    "from transformers import XLNetTokenizer, XLNetModel, XLNetForSequenceClassification # type: ignore\n",
    "from transformers import Trainer, TrainingArguments#type:ignore\n",
    "from sklearn.preprocessing import LabelEncoder #type:ignore\n",
    "from datasets import load_dataset # type: ignore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 19533/19533 [00:00<00:00, 146147.45 examples/s]\n",
      "Generating valid split: 100%|██████████| 2770/2770 [00:00<00:00, 204380.64 examples/s]\n",
      "Generating test split: 100%|██████████| 2547/2547 [00:00<00:00, 215294.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"Estwld/empathetic_dialogues_llm\", cache_dir=\"./cache\")\n",
    "type(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_id': 'hit:53_conv:107', 'situation': 'I really want to win the lottery someday, maybe i will? ', 'emotion': 'hopeful', 'conversations': [{'content': 'So this is going to sound crazy but, one day I am going to win the lottery. ', 'role': 'user'}, {'content': 'That would pretty amazing. What will you do with the winning?', 'role': 'assistant'}, {'content': 'Pay off my debts from moving number 1, and then buy a house! What would you do with the money? ', 'role': 'user'}, {'content': 'I think the same really. Making sure everything is paid off, having a roof over your head, etc... is what most people would want to take caer of first.', 'role': 'assistant'}]}\n",
      "{'conv_id': 'hit:469_conv:939', 'situation': 'Whenever I hear certain songs, it brings back so many memories. Mostly of when I was young and dumb staying up late with friends.', 'emotion': 'nostalgic', 'conversations': [{'content': 'Have you ever heard a song on the radio and it just takes you back to a different time? Like an escape?', 'role': 'user'}, {'content': 'All the time.  That is part of listening to music I suppose.  The songs remind you of when you first heard them.', 'role': 'assistant'}, {'content': \"Yeah, I guess that's fair. It happens all the time to me too. Sometimes makes me wish I was reliving those moments but I don't think I would really want to go back..\", 'role': 'user'}, {'content': 'I know what you mean.  However, the older I get the more I want to go back LOL.', 'role': 'assistant'}, {'content': \"lol :) That's true. Life is hard and did seem so much more carefree when I was younger, but I just don't like who I was. I like me now much better :)\", 'role': 'user'}]}\n",
      "{'conv_id': 'hit:331_conv:663', 'situation': 'I had a huge exam that was coming up, and I study for weeks for it', 'emotion': 'prepared', 'conversations': [{'content': 'I had a huge exam that like 25 percent of my grade. I study for 2 weeks for it', 'role': 'user'}, {'content': 'Oh, I bet that was very stressful and difficult. I hope you did well on it?', 'role': 'assistant'}, {'content': \"Yeah because the professor got mad that the book store didn't have the little blue books to write in, so he canceled it and said whatever our current grade was to bump it up a letter grade\", 'role': 'user'}, {'content': \"Well, at least you didn't go down in your grade. But, it wasn't right to treat the students like that!\", 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "print(ds['train'][91])\n",
    "print(ds['test'][100])\n",
    "print(ds['valid'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['conv_id', 'situation', 'emotion', 'conversations'],\n",
      "        num_rows: 19533\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['conv_id', 'situation', 'emotion', 'conversations'],\n",
      "        num_rows: 2770\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['conv_id', 'situation', 'emotion', 'conversations'],\n",
      "        num_rows: 2547\n",
      "    })\n",
      "})\n",
      "{'conv_id': Value(dtype='string', id=None), 'situation': Value(dtype='string', id=None), 'emotion': Value(dtype='string', id=None), 'conversations': [{'content': Value(dtype='string', id=None), 'role': Value(dtype='string', id=None)}]}\n"
     ]
    }
   ],
   "source": [
    "print(ds)\n",
    "print(ds['train'].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ds['train']\n",
    "type(data)\n",
    "#print(data)\n",
    "#DATA SET IS IN ARROW FORMAT BECAUSE HUGGING FACE USES IT TO EASILY TRANSFER DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONVERTED THE ARROW DATASET INTO PANDAS\n",
    "dftrain = ds['train'].to_pandas()\n",
    "dftest = ds['test'].to_pandas()\n",
    "dfvalid = ds['valid'].to_pandas()\n",
    "type(dftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>situation</th>\n",
       "      <th>emotion</th>\n",
       "      <th>conversations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>[{'content': 'I remember going to see the fire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:1_conv:2</td>\n",
       "      <td>i used to scare for darkness</td>\n",
       "      <td>afraid</td>\n",
       "      <td>[{'content': ' it feels like hitting to blank ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id                                          situation  \\\n",
       "0  hit:0_conv:1  I remember going to the fireworks with my best...   \n",
       "1  hit:1_conv:2                       i used to scare for darkness   \n",
       "\n",
       "       emotion                                      conversations  \n",
       "0  sentimental  [{'content': 'I remember going to see the fire...  \n",
       "1       afraid  [{'content': ' it feels like hitting to blank ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)  \n",
    "dftrain.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_id': 'hit:1_conv:2', 'situation': ' i used to scare for darkness', 'emotion': 'afraid', 'conversations': [{'content': ' it feels like hitting to blank wall when i see the darkness', 'role': 'user'}, {'content': \"Oh ya? I don't really see how\", 'role': 'assistant'}, {'content': 'dont you feel so.. its a wonder ', 'role': 'user'}, {'content': 'I do actually hit blank walls a lot of times but i get by', 'role': 'assistant'}, {'content': ' i virtually thought so.. and i used to get sweatings', 'role': 'user'}, {'content': 'Wait what are sweatings', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "type(data)\n",
    "print(ds['train'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset made into a csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftrain.to_csv(\"dataset_Train.csv\", index=False)\n",
    "#dftest.to_csv(\"dataset_Test.csv\", index= False)\n",
    "#dfvalid.to_csv(\"dataset_Valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\",num_labels = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XLNET RAW OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#independent feature:\n",
    "X = dftrain['situation'].astype(str).to_list()\n",
    "#dependent feature\n",
    "Y = dftrain['emotion']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>annoyed</th>\n",
       "      <th>anticipating</th>\n",
       "      <th>anxious</th>\n",
       "      <th>apprehensive</th>\n",
       "      <th>ashamed</th>\n",
       "      <th>caring</th>\n",
       "      <th>confident</th>\n",
       "      <th>content</th>\n",
       "      <th>devastated</th>\n",
       "      <th>...</th>\n",
       "      <th>joyful</th>\n",
       "      <th>lonely</th>\n",
       "      <th>nostalgic</th>\n",
       "      <th>prepared</th>\n",
       "      <th>proud</th>\n",
       "      <th>sad</th>\n",
       "      <th>sentimental</th>\n",
       "      <th>surprised</th>\n",
       "      <th>terrified</th>\n",
       "      <th>trusting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19528</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19529</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19530</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19531</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19532</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19533 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       angry  annoyed  anticipating  anxious  apprehensive  ashamed  caring  \\\n",
       "0      False    False         False    False         False    False   False   \n",
       "1      False    False         False    False         False    False   False   \n",
       "2      False    False         False    False         False    False   False   \n",
       "3      False    False         False    False         False    False   False   \n",
       "4      False    False         False    False         False    False   False   \n",
       "...      ...      ...           ...      ...           ...      ...     ...   \n",
       "19528  False    False         False    False         False    False   False   \n",
       "19529  False    False          True    False         False    False   False   \n",
       "19530  False    False         False    False         False    False   False   \n",
       "19531  False    False         False    False         False    False   False   \n",
       "19532  False    False         False    False         False    False   False   \n",
       "\n",
       "       confident  content  devastated  ...  joyful  lonely  nostalgic  \\\n",
       "0          False    False       False  ...   False   False      False   \n",
       "1          False    False       False  ...   False   False      False   \n",
       "2          False    False       False  ...   False   False      False   \n",
       "3          False    False       False  ...   False   False      False   \n",
       "4          False    False       False  ...   False   False      False   \n",
       "...          ...      ...         ...  ...     ...     ...        ...   \n",
       "19528      False    False       False  ...   False   False      False   \n",
       "19529      False    False       False  ...   False   False      False   \n",
       "19530      False    False       False  ...   False   False      False   \n",
       "19531      False    False       False  ...   False   False      False   \n",
       "19532      False    False       False  ...   False   False      False   \n",
       "\n",
       "       prepared  proud    sad  sentimental  surprised  terrified  trusting  \n",
       "0         False  False  False         True      False      False     False  \n",
       "1         False  False  False        False      False      False     False  \n",
       "2         False   True  False        False      False      False     False  \n",
       "3         False  False  False        False      False      False     False  \n",
       "4         False  False  False        False      False       True     False  \n",
       "...         ...    ...    ...          ...        ...        ...       ...  \n",
       "19528     False  False  False        False      False      False     False  \n",
       "19529     False  False  False        False      False      False     False  \n",
       "19530     False  False  False        False      False      False     False  \n",
       "19531     False  False  False         True      False      False     False  \n",
       "19532     False  False  False        False       True      False     False  \n",
       "\n",
       "[19533 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(Y,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentimental' 'afraid' 'proud' 'faithful' 'terrified' 'joyful' 'angry'\n",
      " 'sad' 'jealous' 'grateful' 'prepared' 'embarrassed' 'excited' 'annoyed'\n",
      " 'lonely' 'ashamed' 'guilty' 'surprised' 'nostalgic' 'confident' 'furious'\n",
      " 'disappointed' 'caring' 'trusting' 'disgusted' 'anticipating' 'anxious'\n",
      " 'hopeful' 'content' 'impressed' 'apprehensive' 'devastated']\n"
     ]
    }
   ],
   "source": [
    "unique_emotions = dftrain[\"emotion\"].unique()  # List of emotions\n",
    "print(unique_emotions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'afraid': np.int64(0), 'angry': np.int64(1), 'annoyed': np.int64(2), 'anticipating': np.int64(3), 'anxious': np.int64(4), 'apprehensive': np.int64(5), 'ashamed': np.int64(6), 'caring': np.int64(7), 'confident': np.int64(8), 'content': np.int64(9), 'devastated': np.int64(10), 'disappointed': np.int64(11), 'disgusted': np.int64(12), 'embarrassed': np.int64(13), 'excited': np.int64(14), 'faithful': np.int64(15), 'furious': np.int64(16), 'grateful': np.int64(17), 'guilty': np.int64(18), 'hopeful': np.int64(19), 'impressed': np.int64(20), 'jealous': np.int64(21), 'joyful': np.int64(22), 'lonely': np.int64(23), 'nostalgic': np.int64(24), 'prepared': np.int64(25), 'proud': np.int64(26), 'sad': np.int64(27), 'sentimental': np.int64(28), 'surprised': np.int64(29), 'terrified': np.int64(30), 'trusting': np.int64(31)}\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(unique_emotions)\n",
    "corresponding_labels = (dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
    "print(corresponding_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion (Raw Output): 24\n"
     ]
    }
   ],
   "source": [
    "# Move model to device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Function to tokenize input texts\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)  # Convert to PyTorch tensors\n",
    "\n",
    "# Predict function\n",
    "def predict_emotion(situation):\n",
    "    inputs = tokenize_texts([situation])  # Tokenize input\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        outputs = model(**inputs)  # Call the model\n",
    "    \n",
    "    logits = outputs.logits if hasattr(outputs, \"logits\") else outputs[0]\n",
    "    predicted_label = torch.argmax(logits, dim=1).item()  # Get class index\n",
    "    return predicted_label\n",
    "\n",
    "# Example prediction\n",
    "situation_example = \"I lost my job and I feel helpless.\"\n",
    "print(\"Predicted Emotion (Raw Output):\", predict_emotion(situation_example))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['embarrassed']\n"
     ]
    }
   ],
   "source": [
    "keys = [key for key, val in corresponding_labels.items() if val == 13]\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINE TUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aikka\\AppData\\Local\\Temp\\ipykernel_3172\\78884559.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # Output directory\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at each epoch\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",  # Log directory\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "# Initialize Trainer correctly\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dftrain,\n",
    "    eval_dataset=dftest,\n",
    "    tokenizer=tokenizer,  \n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
